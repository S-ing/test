# -*- coding: utf-8 -*-
"""
YOLOv12 Level1 å¢å¼ºç‰ˆæœ¬å®ç°

è¿™æ˜¯YOLOv12çš„Level1å¢å¼ºç‰ˆæœ¬ï¼Œåœ¨Level0åŸºç¡€ä¸Šæ·»åŠ äº†ï¼š
- C3k2æ¨¡å—ï¼šå¢å¼ºçš„CSPæ¨¡å—ï¼Œå…·æœ‰æ›´å¥½çš„ç‰¹å¾æå–èƒ½åŠ›
- SEAttentionï¼šè½»é‡çº§é€šé“æ³¨æ„åŠ›æœºåˆ¶
- ä¿æŒLevel0çš„åŸºç¡€æ¶æ„ï¼Œé€æ­¥å¢å¼ºæ¨¡å‹èƒ½åŠ›

ç›¸æ¯”Level0çš„æ”¹è¿›ï¼š
- ä½¿ç”¨C3k2æ›¿ä»£éƒ¨åˆ†C3kæ¨¡å—ï¼Œæå‡ç‰¹å¾æå–èƒ½åŠ›
- åœ¨å…³é”®ä½ç½®æ·»åŠ SEAttentionï¼Œå¢å¼ºé€šé“ç‰¹å¾è¡¨è¾¾
- ä¿æŒæ¨¡å‹è½»é‡åŒ–ï¼Œå‚æ•°å¢é•¿æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…

ç›®çš„ï¼š
- éªŒè¯å¢å¼ºæ¨¡å—å¯¹æ€§èƒ½çš„æå‡æ•ˆæœ
- ä¸ºåç»­æ›´å¤æ‚ç»„ä»¶çš„æ·»åŠ æä¾›åŸºç¡€
- ä¿æŒè®­ç»ƒç¨³å®šæ€§çš„åŒæ—¶æå‡æ¨¡å‹æ€§èƒ½

Author: YOLOv12 Level1 Implementation
Date: 2025.6.10
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ä»¥æ”¯æŒç»å¯¹å¯¼å…¥
try:
    # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # è·å–YOWOv3é¡¹ç›®æ ¹ç›®å½•ï¼ˆscriptsçš„ä¸Šçº§ç›®å½•ï¼‰
    project_root = os.path.dirname(current_dir)
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    print(f"Added project root to path: {project_root}")
except Exception as e:
    print(f"Error setting up path: {e}")

# å¯¼å…¥DFLæ£€æµ‹å¤´æ¨¡å—
try:
    from model.head.dfl import DFLHead
    print("Successfully imported DFLHead")
except ImportError as e:
    print(f"Warning: Could not import DFLHead: {e}")
    print("This may affect some model components, but training can continue")


def pad(k, p=None, d=1):
    """è®¡ç®—å·ç§¯å±‚çš„å¡«å……å¤§å°"""
    if d > 1:
        k = d * (k - 1) + 1
    if p is None:
        p = k // 2
    return p


def fuse_conv(conv, norm):
    """èåˆå·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–å±‚ä»¥æå‡æ¨ç†é€Ÿåº¦"""
    fused_conv = nn.Conv2d(conv.in_channels,
                           conv.out_channels,
                           kernel_size=conv.kernel_size,
                           stride=conv.stride,
                           padding=conv.padding,
                           groups=conv.groups,
                           bias=True).requires_grad_(False).to(conv.weight.device)

    w_conv = conv.weight.clone().view(conv.out_channels, -1)
    w_norm = torch.diag(norm.weight.div(torch.sqrt(norm.eps + norm.running_var)))
    fused_conv.weight.copy_(torch.mm(w_norm, w_conv).view(fused_conv.weight.size()))

    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias
    b_norm = norm.bias - norm.weight.mul(norm.running_mean).div(torch.sqrt(norm.running_var + norm.eps))
    fused_conv.bias.copy_(torch.mm(w_norm, b_conv.reshape(-1, 1)).reshape(-1) + b_norm)

    return fused_conv


class Conv(nn.Module):
    """æ ‡å‡†å·ç§¯æ¨¡å—"""

    def __init__(self, in_ch, out_ch, k=1, s=1, p=None, d=1, g=1, act=True):
        super().__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, k, s, pad(k, p, d), d, g, False)
        self.norm = nn.BatchNorm2d(out_ch, 0.001, 0.03)
        self.act = nn.SiLU(inplace=True) if act else nn.Identity()

    def forward(self, x):
        return self.act(self.norm(self.conv(x)))

    def fuse_forward(self, x):
        return self.act(self.conv(x))


class Residual(nn.Module):
    """æ®‹å·®æ¨¡å—"""

    def __init__(self, ch, add=True):
        super().__init__()
        self.add_m = add
        self.res_m = nn.Sequential(Conv(ch, ch, 3), Conv(ch, ch, 3))

    def forward(self, x):
        return self.res_m(x) + x if self.add_m else self.res_m(x)


class SEAttention(nn.Module):
    """SEæ³¨æ„åŠ›æœºåˆ¶ - Level1æ–°å¢ç»„ä»¶

    è½»é‡çº§é€šé“æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡å…¨å±€å¹³å‡æ± åŒ–å’Œä¸¤ä¸ªå…¨è¿æ¥å±‚
    å­¦ä¹ é€šé“é—´çš„é‡è¦æ€§æƒé‡ï¼Œæå‡ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚
    """

    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)


class C3k(nn.Module):
    """åŸºç¡€C3kæ¨¡å— - ä»Level0ç»§æ‰¿"""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)
        self.m = nn.Sequential(*(Residual(c_, shortcut) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))


class C3k2(nn.Module):
    """å¢å¼ºçš„C3k2æ¨¡å— - Level1æ–°å¢ç»„ä»¶

    ç›¸æ¯”C3kçš„æ”¹è¿›ï¼š
    - å¢åŠ äº†æ›´å¤šçš„æ®‹å·®è¿æ¥è·¯å¾„
    - æ›´å¥½çš„ç‰¹å¾èåˆæœºåˆ¶
    - å¯é€‰çš„æ³¨æ„åŠ›æœºåˆ¶é›†æˆ
    """

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3, use_se=False):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)

        # å¢å¼ºçš„æ®‹å·®å—åºåˆ—
        self.m = nn.Sequential(*(Residual(c_, shortcut) for _ in range(n)))

        # å¯é€‰çš„SEæ³¨æ„åŠ›æœºåˆ¶
        self.use_se = use_se
        if use_se:
            self.se = SEAttention(c2)

        # é¢å¤–çš„ç‰¹å¾èåˆè·¯å¾„
        self.shortcut = shortcut and c1 == c2

    def forward(self, x):
        # ä¸»è¦çš„ç‰¹å¾æå–è·¯å¾„
        y1 = self.m(self.cv1(x))
        y2 = self.cv2(x)

        # ç‰¹å¾èåˆ
        out = self.cv3(torch.cat((y1, y2), 1))

        # æ®‹å·®è¿æ¥
        if self.shortcut:
            out = out + x

        # SEæ³¨æ„åŠ›
        if self.use_se:
            out = self.se(out)

        return out


class C3k2_SE(nn.Module):
    """é›†æˆSEæ³¨æ„åŠ›çš„C3k2æ¨¡å— - Level1ç»„åˆç»„ä»¶"""

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):
        super().__init__()
        self.c3k2 = C3k2(c1, c2, n, shortcut, g, e, k, use_se=True)

    def forward(self, x):
        return self.c3k2(x)


class SPPF(nn.Module):
    """ç©ºé—´é‡‘å­—å¡”æ± åŒ–æ¨¡å—(SPPF) - ä»Level0ç»§æ‰¿"""

    def __init__(self, in_ch, out_ch, k=5):
        super().__init__()
        self.cv1 = Conv(in_ch, in_ch // 2)
        self.cv2 = Conv(in_ch * 2, out_ch)
        self.pool = nn.MaxPool2d(k, 1, k // 2)

    def forward(self, x):
        x = self.cv1(x)
        y1 = self.pool(x)
        y2 = self.pool(y1)
        return self.cv2(torch.cat([x, y1, y2, self.pool(y2)], 1))


class YOLOv12Backbone_Level1(nn.Module):
    """YOLOv12ä¸»å¹²ç½‘ç»œ - Level1å¢å¼ºç‰ˆæœ¬

    Level1ç‰ˆæœ¬ç‰¹ç‚¹ï¼š
    - åœ¨å…³é”®ä½ç½®ä½¿ç”¨C3k2æ¨¡å—æ›¿ä»£C3k
    - æ·»åŠ SEAttentionå¢å¼ºé€šé“ç‰¹å¾è¡¨è¾¾
    - ä¿æŒLevel0çš„åŸºç¡€æ¶æ„ï¼Œé€æ­¥å¢å¼º
    - å‚æ•°å¢é•¿æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…
    """

    def __init__(self, depth_multiple=0.33, width_multiple=0.25, pretrained=None):
        super().__init__()
        
        # ä¿å­˜é¢„è®­ç»ƒè·¯å¾„ä¾›load_pretrainæ–¹æ³•ä½¿ç”¨
        self.pretrained = pretrained

        # Level1: ä½¿ç”¨ä¸Level0ç›¸åŒçš„é€šé“é…ç½®ï¼Œä½†å¢å¼ºæ¨¡å—èƒ½åŠ›
        def make_divisible(x, divisor=8):
            return math.ceil(x / divisor) * divisor

        # é€šé“é…ç½®ä¸Level0ä¿æŒä¸€è‡´
        base_channels = [64, 128, 256, 512, 1024]
        self.channels = [make_divisible(ch * width_multiple) for ch in base_channels]

        # è®¡ç®—æ·±åº¦å‚æ•°
        def get_depth(n):
            return max(round(n * depth_multiple), 1)

        # Stage 0: è¾“å…¥å¤„ç†
        self.stem = Conv(3, self.channels[0], 6, 2, 2)  # 640 -> 320

        # Stage 1: ç¬¬ä¸€ä¸ªä¸‹é‡‡æ ·é˜¶æ®µ - ä½¿ç”¨åŸºç¡€C3k
        self.stage1 = nn.Sequential(
            Conv(self.channels[0], self.channels[1], 3, 2),  # 320 -> 160
            C3k(self.channels[1], self.channels[1], get_depth(3), True)
        )

        # Stage 2: ç¬¬äºŒä¸ªä¸‹é‡‡æ ·é˜¶æ®µ - å¼€å§‹ä½¿ç”¨C3k2å¢å¼º
        self.stage2 = nn.Sequential(
            Conv(self.channels[1], self.channels[2], 3, 2),  # 160 -> 80
            C3k2(self.channels[2], self.channels[2], get_depth(6), True, use_se=True)  # Level1å¢å¼º
        )

        # Stage 3: ç¬¬ä¸‰ä¸ªä¸‹é‡‡æ ·é˜¶æ®µ - ä½¿ç”¨C3k2_SE
        self.stage3 = nn.Sequential(
            Conv(self.channels[2], self.channels[3], 3, 2),  # 80 -> 40
            C3k2_SE(self.channels[3], self.channels[3], get_depth(6), True)  # Level1å¢å¼º
        )

        # Stage 4: ç¬¬å››ä¸ªä¸‹é‡‡æ ·é˜¶æ®µ - æœ€å¼ºå¢å¼º + SPPF
        self.stage4_conv = Conv(self.channels[3], self.channels[4], 3, 2)  # 40 -> 20
        self.stage4_c3k2 = C3k2_SE(self.channels[4], self.channels[4], get_depth(3), True)  # Level1å¢å¼º
        self.stage4_sppf = SPPF(self.channels[4], self.channels[4])  # ä¿ç•™SPPF

        # é¢å¤–çš„SEæ³¨æ„åŠ›ç”¨äºæœ€ç»ˆç‰¹å¾å¢å¼º
        self.final_se = SEAttention(self.channels[4])

    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼Œè¿”å›å¤šå°ºåº¦ç‰¹å¾"""
        x = self.stem(x)  # Stage 0
        x = self.stage1(x)  # Stage 1

        p3 = self.stage2(x)  # Stage 2 - P3ç‰¹å¾ (80x80) - Level1å¢å¼º
        p4 = self.stage3(p3)  # Stage 3 - P4ç‰¹å¾ (40x40) - Level1å¢å¼º

        # Stage 4 - P5ç‰¹å¾ (20x20) - Level1æœ€å¼ºå¢å¼º
        p5 = self.stage4_conv(p4)
        p5 = self.stage4_c3k2(p5)
        p5 = self.stage4_sppf(p5)
        p5 = self.final_se(p5)  # æœ€ç»ˆSEå¢å¼º

        return p3, p4, p5

    def load_pretrained_weights(self, pretrained_path):
        """åŠ è½½é¢„è®­ç»ƒæƒé‡ - Level1ç‰ˆæœ¬"""
        try:
            print(f"Loading Level1 backbone pretrained weights from: {pretrained_path}")

            if pretrained_path.startswith('http'):
                checkpoint = torch.hub.load_state_dict_from_url(pretrained_path, map_location='cpu')
            else:
                checkpoint = torch.load(pretrained_path, map_location='cpu')

            if 'model' in checkpoint:
                pretrained_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                pretrained_dict = checkpoint['state_dict']
            else:
                pretrained_dict = checkpoint

            # å¤„ç†DetectionModelå¯¹è±¡
            if hasattr(pretrained_dict, 'state_dict'):
                pretrained_dict = pretrained_dict.state_dict()
            elif not isinstance(pretrained_dict, dict):
                print(f"âš ï¸  Unexpected pretrained dict type: {type(pretrained_dict)}")
                print("Attempting to extract state_dict...")
                if hasattr(pretrained_dict, '__dict__'):
                    pretrained_dict = pretrained_dict.__dict__
                else:
                    print("Cannot extract state_dict, skipping pretrained weights")
                    return

            # è·å–å½“å‰æ¨¡å‹çš„state_dict
            model_dict = self.state_dict()

            # Level1ç‰¹æ®Šå¤„ç†ï¼šå°è¯•ä»Level0æƒé‡ä¸­åŠ è½½å…¼å®¹çš„éƒ¨åˆ†
            filtered_dict = {}
            matched_keys = 0
            size_mismatches = []

            for k, v in pretrained_dict.items():
                # ç›´æ¥åŒ¹é…
                if k in model_dict:
                    if v.shape == model_dict[k].shape:
                        filtered_dict[k] = v
                        matched_keys += 1
                    else:
                        size_mismatches.append((k, model_dict[k].shape, v.shape))
                # å°è¯•ä»C3kæ˜ å°„åˆ°C3k2ï¼ˆåŸºç¡€éƒ¨åˆ†ï¼‰
                elif 'c3k2' in k:
                    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„C3kæƒé‡
                    c3k_key = k.replace('c3k2', 'c3k')
                    if c3k_key in pretrained_dict:
                        if pretrained_dict[c3k_key].shape == model_dict[k].shape:
                            filtered_dict[k] = pretrained_dict[c3k_key]
                            matched_keys += 1

            print(f"Level1 Backbone - Successfully matched: {matched_keys} layers")
            if size_mismatches:
                print(f"Level1 Backbone - Size mismatches: {len(size_mismatches)}")

            # æ›´æ–°æ¨¡å‹æƒé‡
            model_dict.update(filtered_dict)
            self.load_state_dict(model_dict, strict=False)

            if matched_keys > 0:
                print(f"âœ… Level1 Backbone - Successfully loaded {matched_keys} layers from pretrained weights")
            else:
                print("âš ï¸  Level1 Backbone - No matching layers found, training from scratch")

        except Exception as e:
            print(f"âŒ Level1 Backbone - Error loading pretrained weights: {str(e)}")
            print("Continuing without pretrained weights...")

    def load_pretrain(self):
        """YOWOv3æ¡†æ¶è¦æ±‚çš„é¢„è®­ç»ƒåŠ è½½æ¥å£"""
        if hasattr(self, 'pretrained') and self.pretrained and self.pretrained != 'None':
            self.load_pretrained_weights(self.pretrained)
        else:
            print("No pretrained weights specified for YOLOv12 Level1")


class YOLOv12NeckHead_Level1(nn.Module):
    """YOLOv12é¢ˆéƒ¨å’Œæ£€æµ‹å¤´ - Level1å¢å¼ºç‰ˆæœ¬

    Level1ç‰ˆæœ¬ç‰¹ç‚¹ï¼š
    - åœ¨FPNè·¯å¾„ä¸­ä½¿ç”¨C3k2æ¨¡å—
    - æ·»åŠ SEæ³¨æ„åŠ›å¢å¼ºç‰¹å¾èåˆ
    - ä¿æŒåŸºç¡€FPNç»“æ„çš„åŒæ—¶æå‡æ€§èƒ½
    """

    def __init__(self, backbone_channels, num_classes=80, depth_multiple=0.33):
        super().__init__()

        def get_depth(n):
            return max(round(n * depth_multiple), 1)

        # ä»backboneè·å–é€šé“æ•°
        p3_ch, p4_ch, p5_ch = backbone_channels

        # Top-down pathway (è‡ªé¡¶å‘ä¸‹è·¯å¾„) - Level1å¢å¼º
        self.upsample = nn.Upsample(None, 2, 'nearest')

        # P5 -> P4 èåˆ - ä½¿ç”¨C3k2å¢å¼º
        self.reduce_p5 = Conv(p5_ch, p4_ch, 1, 1)
        self.c3k2_p4 = C3k2_SE(p4_ch + p4_ch, p4_ch, get_depth(3), False)  # Level1å¢å¼º

        # P4 -> P3 èåˆ - ä½¿ç”¨C3k2å¢å¼º
        self.reduce_p4 = Conv(p4_ch, p3_ch, 1, 1)
        self.c3k2_p3 = C3k2_SE(p3_ch + p3_ch, p3_ch, get_depth(3), False)  # Level1å¢å¼º

        # Bottom-up pathway (è‡ªåº•å‘ä¸Šè·¯å¾„) - Level1å¢å¼º
        # P3 -> P4 èåˆ
        self.downsample_p3 = Conv(p3_ch, p3_ch, 3, 2)
        self.c3k2_p4_out = C3k2_SE(p3_ch + p4_ch, p4_ch, get_depth(3), False)  # Level1å¢å¼º

        # P4 -> P5 èåˆ
        self.downsample_p4 = Conv(p4_ch, p4_ch, 3, 2)
        self.c3k2_p5_out = C3k2_SE(p4_ch + p5_ch, p5_ch, get_depth(3), False)  # Level1å¢å¼º

        # è¾“å‡ºç‰¹å¾çš„SEæ³¨æ„åŠ›å¢å¼º
        self.se_p3 = SEAttention(p3_ch)
        self.se_p4 = SEAttention(p4_ch)
        self.se_p5 = SEAttention(p5_ch)

        # æ£€æµ‹å¤´
        try:
            self.head = DFLHead(num_classes, [p3_ch, p4_ch, p5_ch])
            self.use_dfl_head = True
        except:
            print("Warning: DFLHead not available, using simple detection head")
            self.head = nn.ModuleList([
                nn.Conv2d(p3_ch, num_classes + 4, 1),
                nn.Conv2d(p4_ch, num_classes + 4, 1),
                nn.Conv2d(p5_ch, num_classes + 4, 1)
            ])
            self.use_dfl_head = False

    def forward(self, features):
        """å‰å‘ä¼ æ’­ï¼šå¢å¼ºçš„FPNç‰¹å¾èåˆ + æ£€æµ‹å¤´"""
        p3, p4, p5 = features

        # Top-down pathway - Level1å¢å¼º
        # P5 -> P4
        p5_up = self.upsample(self.reduce_p5(p5))
        p4_fused = self.c3k2_p4(torch.cat([p4, p5_up], 1))  # ä½¿ç”¨C3k2_SE

        # P4 -> P3
        p4_up = self.upsample(self.reduce_p4(p4_fused))
        p3_out = self.c3k2_p3(torch.cat([p3, p4_up], 1))  # ä½¿ç”¨C3k2_SE

        # Bottom-up pathway - Level1å¢å¼º
        # P3 -> P4
        p3_down = self.downsample_p3(p3_out)
        p4_out = self.c3k2_p4_out(torch.cat([p4_fused, p3_down], 1))  # ä½¿ç”¨C3k2_SE

        # P4 -> P5
        p4_down = self.downsample_p4(p4_out)
        p5_out = self.c3k2_p5_out(torch.cat([p5, p4_down], 1))  # ä½¿ç”¨C3k2_SE

        # SEæ³¨æ„åŠ›å¢å¼ºè¾“å‡ºç‰¹å¾
        p3_out = self.se_p3(p3_out)
        p4_out = self.se_p4(p4_out)
        p5_out = self.se_p5(p5_out)

        # æ£€æµ‹å¤´
        if self.use_dfl_head:
            return self.head([p3_out, p4_out, p5_out])
        else:
            # ç®€å•çš„æ£€æµ‹å¤´å®ç°
            return [head(feat) for head, feat in zip(self.head, [p3_out, p4_out, p5_out])]


class YOLO_Level1(nn.Module):
    """YOLOv12å®Œæ•´æ¨¡å‹ - Level1å¢å¼ºç‰ˆæœ¬

    Level1ç‰ˆæœ¬ç‰¹ç‚¹ï¼š
    - åœ¨Level0åŸºç¡€ä¸Šæ·»åŠ C3k2å’ŒSEAttention
    - ä¿æŒåŸºç¡€æ¶æ„ç¨³å®šæ€§
    - é€æ­¥å¢å¼ºæ¨¡å‹æ€§èƒ½
    - å‚æ•°å¢é•¿æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…
    """

    def __init__(self, num_classes=80, depth_multiple=0.33, width_multiple=0.25, pretrained=None):
        super().__init__()

        print(f"Initializing YOLOv12 Level1 with depth_multiple={depth_multiple}, width_multiple={width_multiple}")

        # åˆå§‹åŒ–backbone
        self.backbone = YOLOv12Backbone_Level1(depth_multiple, width_multiple)

        # è·å–backboneè¾“å‡ºé€šé“æ•°
        backbone_channels = self.backbone.channels[-3:]  # P3, P4, P5çš„é€šé“æ•°

        # åˆå§‹åŒ–neckå’Œhead
        self.neck_head = YOLOv12NeckHead_Level1(backbone_channels, num_classes, depth_multiple)

        # ä¸ºYOWOv3æ¡†æ¶å…¼å®¹æ€§æ·»åŠ detection_headå±æ€§
        # æŒ‡å‘neck_headä¸­çš„æ£€æµ‹å¤´éƒ¨åˆ†
        if hasattr(self.neck_head, 'head') and hasattr(self.neck_head.head, 'stride'):
            self.detection_head = self.neck_head.head
        else:
            # å¦‚æœæ²¡æœ‰DFLHeadï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„å…¼å®¹å¯¹è±¡
            class SimpleDetectionHead:
                def __init__(self, nc, no):
                    self.nc = nc  # number of classes
                    self.no = no  # number of outputs per anchor
                    self.stride = torch.tensor([8., 16., 32.])  # é»˜è®¤stride

                    # åˆ›å»ºä¸€ä¸ªç®€å•çš„DFLå¯¹è±¡ç”¨äºå…¼å®¹æ€§
                    class SimpleDFL:
                        def __init__(self):
                            self.ch = 16  # DFL channels

                    self.dfl = SimpleDFL()

            self.detection_head = SimpleDetectionHead(num_classes, num_classes + 4 * 16)

        # ä¿å­˜é…ç½®
        self.num_classes = num_classes
        self.pretrained = pretrained

        # è®¾ç½®è¾“å‡ºé€šé“æ•°ï¼ˆYOWOv3æ¡†æ¶è¦æ±‚ï¼‰
        self.out_channels = backbone_channels  # [P3_ch, P4_ch, P5_ch]

        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if pretrained:
            self.load_pretrained_weights(pretrained)

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        # Backboneç‰¹å¾æå–
        features = self.backbone(x)

        # å¯¹äºYOWOv3é›†æˆï¼Œåªè¿”å›backboneç‰¹å¾ï¼Œä¸è¿›è¡Œæ£€æµ‹
        # YOWOv3æ¡†æ¶ä¼šå¤„ç†åç»­çš„æ£€æµ‹å¤´
        return features

    def load_pretrained_weights(self, pretrained_path):
        """åŠ è½½é¢„è®­ç»ƒæƒé‡ - Level1ç‰ˆæœ¬"""
        try:
            print(f"Loading Level1 pretrained weights from: {pretrained_path}")

            if pretrained_path.startswith('http'):
                checkpoint = torch.hub.load_state_dict_from_url(pretrained_path, map_location='cpu')
            else:
                checkpoint = torch.load(pretrained_path, map_location='cpu')

            if 'model' in checkpoint:
                pretrained_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                pretrained_dict = checkpoint['state_dict']
            else:
                pretrained_dict = checkpoint

            # å¤„ç†DetectionModelå¯¹è±¡
            if hasattr(pretrained_dict, 'state_dict'):
                pretrained_dict = pretrained_dict.state_dict()
            elif not isinstance(pretrained_dict, dict):
                print(f"âš ï¸  Unexpected pretrained dict type: {type(pretrained_dict)}")
                print("Attempting to extract state_dict...")
                if hasattr(pretrained_dict, '__dict__'):
                    pretrained_dict = pretrained_dict.__dict__
                else:
                    print("Cannot extract state_dict, skipping pretrained weights")
                    return

            # è·å–å½“å‰æ¨¡å‹çš„state_dict
            model_dict = self.state_dict()

            # Level1ç‰¹æ®Šå¤„ç†ï¼šå°è¯•ä»Level0æƒé‡ä¸­åŠ è½½å…¼å®¹çš„éƒ¨åˆ†
            filtered_dict = {}
            matched_keys = 0
            size_mismatches = []

            for k, v in pretrained_dict.items():
                # ç›´æ¥åŒ¹é…
                if k in model_dict:
                    if v.shape == model_dict[k].shape:
                        filtered_dict[k] = v
                        matched_keys += 1
                    else:
                        size_mismatches.append((k, model_dict[k].shape, v.shape))
                # å°è¯•ä»C3kæ˜ å°„åˆ°C3k2ï¼ˆåŸºç¡€éƒ¨åˆ†ï¼‰
                elif 'c3k2' in k:
                    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„C3kæƒé‡
                    c3k_key = k.replace('c3k2', 'c3k')
                    if c3k_key in pretrained_dict:
                        if pretrained_dict[c3k_key].shape == model_dict[k].shape:
                            filtered_dict[k] = pretrained_dict[c3k_key]
                            matched_keys += 1

            print(f"Level1 - Successfully matched: {matched_keys} layers")
            if size_mismatches:
                print(f"Level1 - Size mismatches: {len(size_mismatches)}")

            # æ›´æ–°æ¨¡å‹æƒé‡
            model_dict.update(filtered_dict)
            self.load_state_dict(model_dict, strict=False)

            if matched_keys > 0:
                print(f"âœ… Level1 - Successfully loaded {matched_keys} layers from pretrained weights")
            else:
                print("âš ï¸  Level1 - No matching layers found, training from scratch")

        except Exception as e:
            print(f"âŒ Level1 - Error loading pretrained weights: {str(e)}")
            print("Continuing without pretrained weights...")

    def load_pretrain(self):
        """YOWOv3æ¡†æ¶è¦æ±‚çš„é¢„è®­ç»ƒåŠ è½½æ¥å£"""
        if hasattr(self, 'pretrained') and self.pretrained and self.pretrained != 'None':
            self.load_pretrained_weights(self.pretrained)
        else:
            print("No pretrained weights specified for YOLOv12 Level1")

    def fuse(self):
        """èåˆConv2d + BatchNorm2då±‚ä»¥ä¼˜åŒ–æ¨ç†"""
        print("Fusing YOLOv12 Level1 layers...")
        for m in self.modules():
            if isinstance(m, Conv) and hasattr(m, 'norm'):
                m.conv = fuse_conv(m.conv, m.norm)
                delattr(m, 'norm')
                m.forward = m.fuse_forward
        return self


def build_yolov12_level1(version='n', num_classes=80, pretrained=None):
    """æ„å»ºYOLOv12 Level1æ¨¡å‹

    Level1ç‰ˆæœ¬é…ç½®ï¼š
    - åœ¨Level0åŸºç¡€ä¸Šæ·»åŠ C3k2å’ŒSEAttention
    - ä¿æŒåŸºç¡€æ¶æ„ç¨³å®šæ€§
    - é€æ­¥å¢å¼ºæ¨¡å‹æ€§èƒ½
    - é€‚åˆéªŒè¯å¢å¼ºç»„ä»¶çš„æ•ˆæœ

    Args:
        version (str): æ¨¡å‹ç‰ˆæœ¬ ('n', 's', 'm', 'l', 'x')
        num_classes (int): æ£€æµ‹ç±»åˆ«æ•°é‡
        pretrained (str): é¢„è®­ç»ƒæƒé‡è·¯å¾„

    Returns:
        YOLO_Level1: Level1ç‰ˆæœ¬çš„YOLOv12æ¨¡å‹
    """
    # Level1ç‰ˆæœ¬ä½¿ç”¨ä¸Level0ç›¸åŒçš„åŸºç¡€é…ç½®ï¼Œä½†å¢å¼ºæ¨¡å—èƒ½åŠ›
    version_configs = {
        'n': {'depth_multiple': 0.33, 'width_multiple': 0.25},  # å¢å¼ºç‰ˆnano
        's': {'depth_multiple': 0.33, 'width_multiple': 0.50},  # å¢å¼ºç‰ˆsmall
        'm': {'depth_multiple': 0.67, 'width_multiple': 0.75},  # å¢å¼ºç‰ˆmedium
        'l': {'depth_multiple': 1.00, 'width_multiple': 1.00},  # å¢å¼ºç‰ˆlarge
        'x': {'depth_multiple': 1.33, 'width_multiple': 1.25},  # å¢å¼ºç‰ˆextra large
    }

    if version not in version_configs:
        raise ValueError(f"Unsupported version: {version}. Choose from {list(version_configs.keys())}")

    config = version_configs[version]
    depth_multiple = config['depth_multiple']
    width_multiple = config['width_multiple']

    print(f"Building YOLOv12 Level1-{version} with depth_multiple={depth_multiple}, width_multiple={width_multiple}")

    model = YOLO_Level1(
        num_classes=num_classes,
        depth_multiple=depth_multiple,
        width_multiple=width_multiple,
        pretrained=pretrained
    )

    return model


# å¯¼å…¥è®­ç»ƒç›¸å…³æ¨¡å—
import argparse
import yaml
import time
from torch.utils import data
from cus_datasets.build_dataset import build_dataset
from cus_datasets.collate_fn import collate_fn
from model.TSN.YOWOv3 import build_yowov3 
from utils.loss import build_loss
from utils.warmup_lr import LinearWarmup
from utils.EMA import EMA
import shutil
from utils.flops import get_info


def train_level1_model(config):
    """
    Train YOLOv12 Level1 model with YOWOv3 framework
    
    Args:
        config (dict): Configuration dictionary containing all training parameters
    """
    
    print("ğŸš€ Starting YOLOv12 Level1 Training...")
    print(f"ğŸ“ Save folder: {config['save_folder']}")
    print(f"ğŸ¯ Dataset: {config['dataset']}")
    print(f"ğŸ“Š Batch size: {config['batch_size']}")
    print(f"ğŸ”„ Max epochs: {config['max_epoch']}")
    
    # Create save directory
    os.makedirs(config['save_folder'], exist_ok=True)
    
    # Save config file
    #######################################################
    source_file = config['config_path']
    destination_file = os.path.join(config['save_folder'], 'config.yaml')
    shutil.copyfile(source_file, destination_file)
    print(f"ğŸ’¾ Config saved to: {destination_file}")
    #######################################################
    
    # Create dataloader, model, criterion
    ####################################################
    print("ğŸ“š Building dataset...")
    dataset = build_dataset(config, phase='train')
    
    dataloader = data.DataLoader(dataset, config['batch_size'], True, collate_fn=collate_fn,
                                 num_workers=config['num_workers'], pin_memory=True)
    
    print("ğŸ—ï¸  Building YOLOv12 Level1 model...")
    model = build_yowov3(config)
    
    # Get model information
    get_info(config, model)
    
    # Print Level1 specific information
    if hasattr(model.net2D, 'backbone'):
        backbone_params = sum(p.numel() for p in model.net2D.backbone.parameters())
        print(f"ğŸ§  Level1 Backbone parameters: {backbone_params:,}")
    
    model.to("cuda")
    model.train()
    
    print("ğŸ¯ Building loss function...")
    criterion = build_loss(model, config)
    #####################################################

    # Optimizer setup with parameter grouping
    print("âš™ï¸  Setting up optimizer...")
    
    # Parameter grouping for different learning rates
    backbone_params = []
    neck_params = []
    head_params = []
    
    for name, param in model.named_parameters():
        if 'backbone' in name or 'net2D' in name:
            backbone_params.append(param)
        elif 'neck' in name or 'fpn' in name:
            neck_params.append(param)
        else:
            head_params.append(param)
    
    # Different learning rates for different parts
    param_groups = [
        {'params': backbone_params, 'lr': config['lr'] * 0.1},  # Lower LR for backbone
        {'params': neck_params, 'lr': config['lr']},
        {'params': head_params, 'lr': config['lr']}
    ]
    
    optimizer = torch.optim.AdamW(param_groups, 
                                  lr=config['lr'], 
                                  weight_decay=config['weight_decay'])
    
    # Training parameters
    adjustlr_schedule = config['adjustlr_schedule']
    acc_grad = config['acc_grad']
    lr_decay = config['lr_decay']
    
    # Warmup scheduler
    warmup_lr = LinearWarmup(config)
    
    print(f"ğŸ“ˆ Optimizer: AdamW with {len(param_groups)} parameter groups")
    print(f"ğŸ”¥ Learning rate: {config['lr']} (backbone: {config['lr'] * 0.1})")
    print(f"ğŸŒ¡ï¸  Warmup steps: {config['max_step_warmup']}")
    
    # Initialize training variables
    cnt_pram_update = 0
    ema = EMA(model)
    
    # Training loop
    print("\nğŸ¯ Starting Level1 training loop...")
    
    best_map = 0.0
    start_time = time.time()
    
    for epoch in range(config['max_epoch']):
        epoch_start_time = time.time()
        
        # Training phase
        model.train()
        epoch_loss = 0.0
        loss_acc = 0.0
        num_batches = 0
        
        print(f"\nğŸ“… Epoch [{epoch+1}/{config['max_epoch']}]")
        
        for batch_idx, (batch_clip, batch_bboxes, batch_labels) in enumerate(dataloader):
            # Move to GPU
            batch_size = batch_clip.shape[0]
            batch_clip = batch_clip.cuda()
            
            for idx in range(batch_size):
                batch_bboxes[idx] = batch_bboxes[idx].cuda()
                batch_labels[idx] = batch_labels[idx].cuda()
            
            # Forward pass
            outputs = model(batch_clip)
            
            # Build targets
            targets = []
            for i, (bboxes, labels) in enumerate(zip(batch_bboxes, batch_labels)):
                nbox = bboxes.shape[0]
                nclass = labels.shape[1]
                target = torch.Tensor(nbox, 5 + nclass)
                target[:, 0] = i
                target[:, 1:5] = bboxes
                target[:, 5:] = labels
                targets.append(target)
            
            targets = torch.cat(targets, dim=0)
            
            # Compute loss
            loss = criterion(outputs, targets) / acc_grad
            total_loss = loss
            
            # Backward pass
            loss_acc += loss.item()
            epoch_loss += loss.item()
            num_batches += 1
            
            loss.backward()
            
            if (batch_idx + 1) % acc_grad == 0:
                cnt_pram_update = cnt_pram_update + 1
                if epoch == 0:  # First epoch warmup
                    warmup_lr(optimizer, cnt_pram_update)
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
                
                optimizer.step()
                optimizer.zero_grad()
                ema.update(model)
            
            # Print progress
            if (batch_idx + 1) % acc_grad == 0:
                current_lr = optimizer.param_groups[0]['lr']
                loss_acc += loss.item()
                print(f"Epoch: {epoch + 1}, Update: {cnt_pram_update}, Loss: {loss_acc:.6f}, LR: {current_lr:.8f}", flush=True)
                
                # Log to file
                with open(os.path.join(config['save_folder'], "training_log.txt"), "a") as f:
                    f.write(f"Epoch: {epoch + 1}, Update: {cnt_pram_update}, Loss: {loss_acc:.6f}, LR: {current_lr:.8f}\n")

                loss_acc = 0.0
        
        # Learning rate scheduling (after warmup)
        if epoch >= 1 and (epoch + 1) in adjustlr_schedule:
            old_lr = optimizer.param_groups[0]['lr']
            for param_group in optimizer.param_groups:
                param_group['lr'] *= lr_decay
            new_lr = optimizer.param_groups[0]['lr']
            print(f"     ğŸ“‰ Learning rate adjusted: {old_lr:.8f} -> {new_lr:.8f}")
        
        # Calculate average loss
        avg_loss = epoch_loss / num_batches
        epoch_time = time.time() - epoch_start_time
        
        print(f"  ğŸ“Š Epoch {epoch+1} Summary:")
        print(f"     Average Loss: {avg_loss:.4f}")
        print(f"     Time: {epoch_time:.2f}s")
        print(f"     LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # Save checkpoint every epoch (like Level0)
        # Save EMA model
        ema_path = os.path.join(config['save_folder'], f'level1_ema_epoch_{epoch+1}.pth')
        torch.save(ema.ema.state_dict(), ema_path)
        
        # Save regular model
        checkpoint_path = os.path.join(config['save_folder'], f'level1_epoch_{epoch+1}.pth')
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': avg_loss,
            'config': config
        }, checkpoint_path)
        print(f"     ğŸ’¾ Model saved: {checkpoint_path}")
        print(f"     ğŸ’¾ EMA model saved: {ema_path}")
    
    # Save final model
    final_model_path = os.path.join(config['save_folder'], 'final_model.pth')
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config,
        'training_completed': True
    }, final_model_path)
    
    total_time = time.time() - start_time
    print(f"\nâœ… Level1 training completed!")
    print(f"â±ï¸  Total training time: {total_time/3600:.2f} hours")
    print(f"ğŸ’¾ Final model saved: {final_model_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='YOLOv12 Level1 Training')
    parser.add_argument('--config', type=str, required=True, help='Path to config file')
    parser.add_argument('--test_only', action='store_true', help='Only test model without training')
    
    args = parser.parse_args()
    
    # Load configuration
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    
    # Add config path to config dict
    config['config_path'] = args.config
    
    if args.test_only:
        # æµ‹è¯•Level1æ¨¡å‹
        print("Testing YOLOv12 Level1 model...")

        # åˆ›å»ºæ¨¡å‹
        model = build_yolov12_level1('n', num_classes=80)

        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(1, 3, 640, 640)

        with torch.no_grad():
            outputs = model(x)
            print(f"Input shape: {x.shape}")
            if isinstance(outputs, list) or isinstance(outputs, tuple):
                for i, output in enumerate(outputs):
                    print(f"Output {i} shape: {output.shape}")
            else:
                print(f"Output shape: {outputs.shape}")

        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

        print(f"\nModel Statistics:")
        print(f"Total parameters: {total_params:,}")
        print(f"Trainable parameters: {trainable_params:,}")
        print(f"Model size: {total_params * 4 / 1024 / 1024:.2f} MB")

        # ä¸Level0å¯¹æ¯”
        try:
            from YOLOv12_Level0 import build_yolov12_level0

            level0_model = build_yolov12_level0('n', num_classes=80)
            level0_params = sum(p.numel() for p in level0_model.parameters())

            param_increase = (total_params - level0_params) / level0_params * 100
            print(f"\nComparison with Level0:")
            print(f"Level0 parameters: {level0_params:,}")
            print(f"Level1 parameters: {total_params:,}")
            print(f"Parameter increase: {param_increase:.2f}%")

        except ImportError:
            print("\nCannot import Level0 for comparison")

        print("\nâœ… YOLOv12 Level1 model test completed successfully!")
    else:
        # Start training
        train_level1_model(config)